{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#from keras.src import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af0e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign count: 1416\n",
      "Malignant count: 4174\n",
      "Test set: 1118 images (Benign: 283, Malignant: 835)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths\n",
    "image_path_base = r'C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\png'\n",
    "text_path_base = r'C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\myver_cleanCropCMMD.csv'\n",
    "model_weights_path = r'C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\weights\\best_model_oversampled.h5'\n",
    "\n",
    "def get_image_paths_and_labels():\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    b_count = 0\n",
    "    m_count = 0\n",
    "\n",
    "    with open(text_path_base) as f:\n",
    "        f.readline()\n",
    "\n",
    "        for line in f:\n",
    "            splitLine = line.split(\",\")\n",
    "\n",
    "            imagePath = splitLine[2].replace(\"\\n\", \"\").replace('\"',\"\") \n",
    "            image_paths.append(imagePath)\n",
    "\n",
    "            classification = splitLine[1].replace('\"', '') \n",
    "            if classification == \"0\":\n",
    "              labels.append(np.array([0]))\n",
    "              b_count += 1\n",
    "            if classification == \"1\":\n",
    "              labels.append(np.array([1]))\n",
    "              m_count += 1\n",
    "\n",
    "    print(f\"Benign count: {b_count}\")\n",
    "    print(f\"Malignant count: {m_count}\")\n",
    "    return np.array(image_paths), np.array(labels)\n",
    "\n",
    "image_paths, labels = get_image_paths_and_labels()\n",
    "\n",
    "paths_train, paths_test, y_train, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=1, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Test set: {len(paths_test)} images (Benign: {np.sum(y_test == 0)}, Malignant: {np.sum(y_test == 1)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e77c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator:\n",
    "    def __init__(self, image_paths, labels, batch_size=32, augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_images = []\n",
    "        for path in batch_paths:\n",
    "\n",
    "            img = load_img(path, color_mode='rgb')\n",
    "            img_array = img_to_array(img)\n",
    "            img_tensor = tf.convert_to_tensor(img_array)\n",
    "            img = tf.image.resize_with_pad(img_tensor, 600, 600)\n",
    "            batch_images.append(img)\n",
    "\n",
    "        X = np.array(batch_images)\n",
    "        y = np.array(batch_labels).reshape(-1, 1)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def generate(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self.__getitem__(i)\n",
    "\n",
    "test_gen = TestDataGenerator(paths_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3b36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(600, 600, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429c8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a58b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Oversampled_ResNet50 Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.44      0.28      0.34       283\n",
      "   Malignant       0.78      0.88      0.83       835\n",
      "\n",
      "    accuracy                           0.73      1118\n",
      "   macro avg       0.61      0.58      0.59      1118\n",
      "weighted avg       0.70      0.73      0.71      1118\n",
      "\n",
      "Confusion matrix saved to: C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\result3_oversampled\\oversampled_finished_confusion_matrix.png\n",
      "ROC curve saved to: C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\result3_oversampled\\oversampled_finished_roc_curve.png\n",
      "\n",
      " Final Accuracy: 0.7281, AUC: 0.6854\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 79 204]\n",
      " [100 735]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load best saved weights\n",
    "#model.load_weights(r'C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\weights\\best_model.weights.h5')\n",
    "\n",
    "def evaluate_model(model, generator, steps, model_name=\"Model\"):\n",
    "    if hasattr(generator, 'on_epoch_end'):\n",
    "        generator.on_epoch_end()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred_prob = []\n",
    "    \n",
    "    for i in range(steps):\n",
    "        if hasattr(generator, '__getitem__'):\n",
    "            batch_x, batch_y = generator.__getitem__(i)\n",
    "        else:\n",
    "            batch_x, batch_y = next(generator.generate())\n",
    "            \n",
    "        batch_pred = model.predict(batch_x, verbose=0)\n",
    "        \n",
    "        y_true.extend(batch_y)\n",
    "        y_pred_prob.extend(batch_pred)\n",
    "\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred_prob = np.array(y_pred_prob).flatten()\n",
    "    \n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # --- Classification Report ---\n",
    "    print(f\"\\n--- {model_name} Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Benign', 'Malignant']))\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, ['Benign', 'Malignant'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Benign', 'Malignant'])\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cm_path = fr'C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\result3_oversampled\\oversampled_finished_confusion_matrix.png'\n",
    "    plt.savefig(cm_path)\n",
    "    print(f\"Confusion matrix saved to: {cm_path}\")\n",
    "    plt.close()\n",
    "\n",
    "    # --- ROC Curve ---\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    roc_path = fr'C:\\Users\\yaruu\\OneDrive\\Documents\\DIS Copenhagen 2025\\Courses\\ANN & DL\\Final Project\\Datasets\\CMMD_Clean\\result3_oversampled\\oversampled_finished_roc_curve.png'\n",
    "    plt.savefig(roc_path)\n",
    "    print(f\"ROC curve saved to: {roc_path}\")\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        'accuracy': (y_pred == y_true).mean(),\n",
    "        'auc': roc_auc,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_prob': y_pred_prob,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "results = evaluate_model(model, test_gen, len(test_gen), model_name=\"Oversampled_ResNet50\")\n",
    "\n",
    "print(f\"\\n Final Accuracy: {results['accuracy']:.4f}, AUC: {results['auc']:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(results['confusion_matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
